{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../resnet/\")\n",
    "from resnet import ResNet\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../resnet/resnet.py:138: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight)\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270410"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"../../smoothed_geometry/example/weights/resnet20_ssr1_3.h5\", \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_1\n",
      "activation_10\n",
      "activation_11\n",
      "activation_12\n",
      "activation_13\n",
      "activation_14\n",
      "activation_15\n",
      "activation_16\n",
      "activation_17\n",
      "activation_18\n",
      "activation_19\n",
      "activation_2\n",
      "activation_20\n",
      "activation_3\n",
      "activation_4\n",
      "activation_5\n",
      "activation_6\n",
      "activation_7\n",
      "activation_8\n",
      "activation_9\n",
      "add_1\n",
      "add_2\n",
      "add_3\n",
      "add_4\n",
      "add_5\n",
      "add_6\n",
      "add_7\n",
      "add_8\n",
      "add_9\n",
      "average_pooling2d_1\n",
      "batch_normalization_1\n",
      "beta:0\n",
      "(16,)\n",
      "gamma:0\n",
      "(16,)\n",
      "moving_mean:0\n",
      "(16,)\n",
      "moving_variance:0\n",
      "(16,)\n",
      "batch_normalization_10\n",
      "beta:0\n",
      "(32,)\n",
      "gamma:0\n",
      "(32,)\n",
      "moving_mean:0\n",
      "(32,)\n",
      "moving_variance:0\n",
      "(32,)\n",
      "batch_normalization_11\n",
      "beta:0\n",
      "(32,)\n",
      "gamma:0\n",
      "(32,)\n",
      "moving_mean:0\n",
      "(32,)\n",
      "moving_variance:0\n",
      "(32,)\n",
      "batch_normalization_12\n",
      "beta:0\n",
      "(32,)\n",
      "gamma:0\n",
      "(32,)\n",
      "moving_mean:0\n",
      "(32,)\n",
      "moving_variance:0\n",
      "(32,)\n",
      "batch_normalization_13\n",
      "beta:0\n",
      "(32,)\n",
      "gamma:0\n",
      "(32,)\n",
      "moving_mean:0\n",
      "(32,)\n",
      "moving_variance:0\n",
      "(32,)\n",
      "batch_normalization_14\n",
      "beta:0\n",
      "(64,)\n",
      "gamma:0\n",
      "(64,)\n",
      "moving_mean:0\n",
      "(64,)\n",
      "moving_variance:0\n",
      "(64,)\n",
      "batch_normalization_15\n",
      "beta:0\n",
      "(64,)\n",
      "gamma:0\n",
      "(64,)\n",
      "moving_mean:0\n",
      "(64,)\n",
      "moving_variance:0\n",
      "(64,)\n",
      "batch_normalization_16\n",
      "beta:0\n",
      "(64,)\n",
      "gamma:0\n",
      "(64,)\n",
      "moving_mean:0\n",
      "(64,)\n",
      "moving_variance:0\n",
      "(64,)\n",
      "batch_normalization_17\n",
      "beta:0\n",
      "(64,)\n",
      "gamma:0\n",
      "(64,)\n",
      "moving_mean:0\n",
      "(64,)\n",
      "moving_variance:0\n",
      "(64,)\n",
      "batch_normalization_18\n",
      "beta:0\n",
      "(64,)\n",
      "gamma:0\n",
      "(64,)\n",
      "moving_mean:0\n",
      "(64,)\n",
      "moving_variance:0\n",
      "(64,)\n",
      "batch_normalization_19\n",
      "beta:0\n",
      "(64,)\n",
      "gamma:0\n",
      "(64,)\n",
      "moving_mean:0\n",
      "(64,)\n",
      "moving_variance:0\n",
      "(64,)\n",
      "batch_normalization_2\n",
      "beta:0\n",
      "(16,)\n",
      "gamma:0\n",
      "(16,)\n",
      "moving_mean:0\n",
      "(16,)\n",
      "moving_variance:0\n",
      "(16,)\n",
      "batch_normalization_3\n",
      "beta:0\n",
      "(16,)\n",
      "gamma:0\n",
      "(16,)\n",
      "moving_mean:0\n",
      "(16,)\n",
      "moving_variance:0\n",
      "(16,)\n",
      "batch_normalization_4\n",
      "beta:0\n",
      "(16,)\n",
      "gamma:0\n",
      "(16,)\n",
      "moving_mean:0\n",
      "(16,)\n",
      "moving_variance:0\n",
      "(16,)\n",
      "batch_normalization_5\n",
      "beta:0\n",
      "(16,)\n",
      "gamma:0\n",
      "(16,)\n",
      "moving_mean:0\n",
      "(16,)\n",
      "moving_variance:0\n",
      "(16,)\n",
      "batch_normalization_6\n",
      "beta:0\n",
      "(16,)\n",
      "gamma:0\n",
      "(16,)\n",
      "moving_mean:0\n",
      "(16,)\n",
      "moving_variance:0\n",
      "(16,)\n",
      "batch_normalization_7\n",
      "beta:0\n",
      "(16,)\n",
      "gamma:0\n",
      "(16,)\n",
      "moving_mean:0\n",
      "(16,)\n",
      "moving_variance:0\n",
      "(16,)\n",
      "batch_normalization_8\n",
      "beta:0\n",
      "(32,)\n",
      "gamma:0\n",
      "(32,)\n",
      "moving_mean:0\n",
      "(32,)\n",
      "moving_variance:0\n",
      "(32,)\n",
      "batch_normalization_9\n",
      "beta:0\n",
      "(32,)\n",
      "gamma:0\n",
      "(32,)\n",
      "moving_mean:0\n",
      "(32,)\n",
      "moving_variance:0\n",
      "(32,)\n",
      "conv2d_1\n",
      "bias:0\n",
      "(16,)\n",
      "kernel:0\n",
      "(3, 3, 3, 16)\n",
      "conv2d_10\n",
      "bias:0\n",
      "(32,)\n",
      "kernel:0\n",
      "(1, 1, 16, 32)\n",
      "conv2d_11\n",
      "bias:0\n",
      "(32,)\n",
      "kernel:0\n",
      "(3, 3, 32, 32)\n",
      "conv2d_12\n",
      "bias:0\n",
      "(32,)\n",
      "kernel:0\n",
      "(3, 3, 32, 32)\n",
      "conv2d_13\n",
      "bias:0\n",
      "(32,)\n",
      "kernel:0\n",
      "(3, 3, 32, 32)\n",
      "conv2d_14\n",
      "bias:0\n",
      "(32,)\n",
      "kernel:0\n",
      "(3, 3, 32, 32)\n",
      "conv2d_15\n",
      "bias:0\n",
      "(64,)\n",
      "kernel:0\n",
      "(3, 3, 32, 64)\n",
      "conv2d_16\n",
      "bias:0\n",
      "(64,)\n",
      "kernel:0\n",
      "(3, 3, 64, 64)\n",
      "conv2d_17\n",
      "bias:0\n",
      "(64,)\n",
      "kernel:0\n",
      "(1, 1, 32, 64)\n",
      "conv2d_18\n",
      "bias:0\n",
      "(64,)\n",
      "kernel:0\n",
      "(3, 3, 64, 64)\n",
      "conv2d_19\n",
      "bias:0\n",
      "(64,)\n",
      "kernel:0\n",
      "(3, 3, 64, 64)\n",
      "conv2d_2\n",
      "bias:0\n",
      "(16,)\n",
      "kernel:0\n",
      "(3, 3, 16, 16)\n",
      "conv2d_20\n",
      "bias:0\n",
      "(64,)\n",
      "kernel:0\n",
      "(3, 3, 64, 64)\n",
      "conv2d_21\n",
      "bias:0\n",
      "(64,)\n",
      "kernel:0\n",
      "(3, 3, 64, 64)\n",
      "conv2d_3\n",
      "bias:0\n",
      "(16,)\n",
      "kernel:0\n",
      "(3, 3, 16, 16)\n",
      "conv2d_4\n",
      "bias:0\n",
      "(16,)\n",
      "kernel:0\n",
      "(3, 3, 16, 16)\n",
      "conv2d_5\n",
      "bias:0\n",
      "(16,)\n",
      "kernel:0\n",
      "(3, 3, 16, 16)\n",
      "conv2d_6\n",
      "bias:0\n",
      "(16,)\n",
      "kernel:0\n",
      "(3, 3, 16, 16)\n",
      "conv2d_7\n",
      "bias:0\n",
      "(16,)\n",
      "kernel:0\n",
      "(3, 3, 16, 16)\n",
      "conv2d_8\n",
      "bias:0\n",
      "(32,)\n",
      "kernel:0\n",
      "(3, 3, 16, 32)\n",
      "conv2d_9\n",
      "bias:0\n",
      "(32,)\n",
      "kernel:0\n",
      "(3, 3, 32, 32)\n",
      "dense_1\n",
      "bias:0\n",
      "(10,)\n",
      "kernel:0\n",
      "(64, 10)\n",
      "flatten_1\n",
      "input_1\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for layer, group in f.items():\n",
    "    print(layer)\n",
    "    for p_name in group.keys():\n",
    "        param = group[p_name]\n",
    "        for k_name in param.keys():\n",
    "            print(k_name)\n",
    "            print(param[k_name].shape)\n",
    "            i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16, 1, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"conv2d_10\"][\"conv2d_10\"][\"kernel:0\"][:].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12704657, 0.88938755, 0.1391233 , 0.16750452, 0.79546124,\n",
       "       1.0130746 , 0.40594456, 1.0238892 , 1.0054772 , 1.5747428 ,\n",
       "       0.34093332, 1.3006516 , 1.0709275 , 0.2351042 , 0.8880941 ,\n",
       "       0.5203876 ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"batch_normalization_1\"][\"batch_normalization_1\"][\"beta:0\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (convIn): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bnIn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (stack1): ModuleList(\n",
       "    (0): block(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "    )\n",
       "    (1): block(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "    )\n",
       "    (2): block(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "    )\n",
       "  )\n",
       "  (stack2a): block(\n",
       "    (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU()\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU()\n",
       "    (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "  )\n",
       "  (stack2b): ModuleList(\n",
       "    (0): block(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "    )\n",
       "    (1): block(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "    )\n",
       "  )\n",
       "  (stack3a): block(\n",
       "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU()\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU()\n",
       "    (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "  )\n",
       "  (stack3b): ModuleList(\n",
       "    (0): block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "    )\n",
       "    (1): block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU()\n",
       "      (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fcOut): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 3, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stack3b[1].conv2.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the weights\n",
    "model.convIn.weight.data = torch.tensor(f[\"conv2d_1\"][\"conv2d_1\"][\"kernel:0\"][:].T)\n",
    "model.convIn.bias.data = torch.tensor(f[\"conv2d_1\"][\"conv2d_1\"][\"bias:0\"][:])\n",
    "#\n",
    "model.bnIn.bias.data = torch.tensor(f[\"batch_normalization_1\"][\"batch_normalization_1\"][\"beta:0\"][:])\n",
    "model.bnIn.weight.data = torch.tensor(f[\"batch_normalization_1\"][\"batch_normalization_1\"][\"gamma:0\"][:])\n",
    "model.bnIn.running_mean.data = torch.tensor(f[\"batch_normalization_1\"][\"batch_normalization_1\"][\"moving_mean:0\"][:])\n",
    "model.bnIn.running_var.data = torch.tensor(f[\"batch_normalization_1\"][\"batch_normalization_1\"][\"moving_variance:0\"][:])\n",
    "# stack1\n",
    "s1 = model.stack1\n",
    "s1[0].conv1.weight.data = torch.tensor(f[\"conv2d_2\"][\"conv2d_2\"][\"kernel:0\"][:].T)\n",
    "s1[0].conv1.bias.data = torch.tensor(f[\"conv2d_2\"][\"conv2d_2\"][\"bias:0\"][:])\n",
    "#\n",
    "s1[0].bn1.bias.data = torch.tensor(f[\"batch_normalization_2\"][\"batch_normalization_2\"][\"beta:0\"][:])\n",
    "s1[0].bn1.weight.data = torch.tensor(f[\"batch_normalization_2\"][\"batch_normalization_2\"][\"gamma:0\"][:])\n",
    "s1[0].bn1.running_mean.data = torch.tensor(f[\"batch_normalization_2\"][\"batch_normalization_2\"][\"moving_mean:0\"][:])\n",
    "s1[0].bn1.running_var.data = torch.tensor(f[\"batch_normalization_2\"][\"batch_normalization_2\"][\"moving_variance:0\"][:])\n",
    "#\n",
    "s1[0].conv2.weight.data = torch.tensor(f[\"conv2d_3\"][\"conv2d_3\"][\"kernel:0\"][:].T)\n",
    "s1[0].conv2.bias.data = torch.tensor(f[\"conv2d_3\"][\"conv2d_3\"][\"bias:0\"][:])\n",
    "#\n",
    "s1[0].bn2.bias.data = torch.tensor(f[\"batch_normalization_3\"][\"batch_normalization_3\"][\"beta:0\"][:])\n",
    "s1[0].bn2.weight.data = torch.tensor(f[\"batch_normalization_3\"][\"batch_normalization_3\"][\"gamma:0\"][:])\n",
    "s1[0].bn2.running_mean.data = torch.tensor(f[\"batch_normalization_3\"][\"batch_normalization_3\"][\"moving_mean:0\"][:])\n",
    "s1[0].bn2.running_var.data = torch.tensor(f[\"batch_normalization_3\"][\"batch_normalization_3\"][\"moving_variance:0\"][:])\n",
    "##########\n",
    "s1[1].conv1.weight.data = torch.tensor(f[\"conv2d_4\"][\"conv2d_4\"][\"kernel:0\"][:].T)\n",
    "s1[1].conv1.bias.data = torch.tensor(f[\"conv2d_4\"][\"conv2d_4\"][\"bias:0\"][:])\n",
    "#\n",
    "s1[1].bn1.bias.data = torch.tensor(f[\"batch_normalization_4\"][\"batch_normalization_4\"][\"beta:0\"][:])\n",
    "s1[1].bn1.weight.data = torch.tensor(f[\"batch_normalization_4\"][\"batch_normalization_4\"][\"gamma:0\"][:])\n",
    "s1[1].bn1.running_mean.data = torch.tensor(f[\"batch_normalization_4\"][\"batch_normalization_4\"][\"moving_mean:0\"][:])\n",
    "s1[1].bn1.running_var.data = torch.tensor(f[\"batch_normalization_4\"][\"batch_normalization_4\"][\"moving_variance:0\"][:])\n",
    "#\n",
    "s1[1].conv2.weight.data = torch.tensor(f[\"conv2d_5\"][\"conv2d_5\"][\"kernel:0\"][:].T)\n",
    "s1[1].conv2.bias.data = torch.tensor(f[\"conv2d_5\"][\"conv2d_5\"][\"bias:0\"][:])\n",
    "#\n",
    "s1[1].bn2.bias.data = torch.tensor(f[\"batch_normalization_5\"][\"batch_normalization_5\"][\"beta:0\"][:])\n",
    "s1[1].bn2.weight.data = torch.tensor(f[\"batch_normalization_5\"][\"batch_normalization_5\"][\"gamma:0\"][:])\n",
    "s1[1].bn2.running_mean.data = torch.tensor(f[\"batch_normalization_5\"][\"batch_normalization_5\"][\"moving_mean:0\"][:])\n",
    "s1[1].bn2.running_var.data = torch.tensor(f[\"batch_normalization_5\"][\"batch_normalization_5\"][\"moving_variance:0\"][:])\n",
    "###########\n",
    "s1[2].conv1.weight.data = torch.tensor(f[\"conv2d_6\"][\"conv2d_6\"][\"kernel:0\"][:].T)\n",
    "s1[2].conv1.bias.data = torch.tensor(f[\"conv2d_6\"][\"conv2d_6\"][\"bias:0\"][:])\n",
    "#\n",
    "s1[2].bn1.bias.data = torch.tensor(f[\"batch_normalization_6\"][\"batch_normalization_6\"][\"beta:0\"][:])\n",
    "s1[2].bn1.weight.data = torch.tensor(f[\"batch_normalization_6\"][\"batch_normalization_6\"][\"gamma:0\"][:])\n",
    "s1[2].bn1.running_mean.data = torch.tensor(f[\"batch_normalization_6\"][\"batch_normalization_6\"][\"moving_mean:0\"][:])\n",
    "s1[2].bn1.running_var.data = torch.tensor(f[\"batch_normalization_6\"][\"batch_normalization_6\"][\"moving_variance:0\"][:])\n",
    "#\n",
    "s1[2].conv2.weight.data = torch.tensor(f[\"conv2d_7\"][\"conv2d_7\"][\"kernel:0\"][:].T)\n",
    "s1[2].conv2.bias.data = torch.tensor(f[\"conv2d_7\"][\"conv2d_7\"][\"bias:0\"][:])\n",
    "#\n",
    "s1[2].bn2.bias.data = torch.tensor(f[\"batch_normalization_7\"][\"batch_normalization_7\"][\"beta:0\"][:])\n",
    "s1[2].bn2.weight.data = torch.tensor(f[\"batch_normalization_7\"][\"batch_normalization_7\"][\"gamma:0\"][:])\n",
    "s1[2].bn2.running_mean.data = torch.tensor(f[\"batch_normalization_7\"][\"batch_normalization_7\"][\"moving_mean:0\"][:])\n",
    "s1[2].bn2.running_var.data = torch.tensor(f[\"batch_normalization_7\"][\"batch_normalization_7\"][\"moving_variance:0\"][:])\n",
    "# stack 2a\n",
    "s2a = model.stack2a\n",
    "s2a.conv1.weight.data = torch.tensor(f[\"conv2d_8\"][\"conv2d_8\"][\"kernel:0\"][:].T)\n",
    "s2a.conv1.bias.data = torch.tensor(f[\"conv2d_8\"][\"conv2d_8\"][\"bias:0\"][:])\n",
    "#\n",
    "s2a.bn1.bias.data = torch.tensor(f[\"batch_normalization_8\"][\"batch_normalization_8\"][\"beta:0\"][:])\n",
    "s2a.bn1.weight.data = torch.tensor(f[\"batch_normalization_8\"][\"batch_normalization_8\"][\"gamma:0\"][:])\n",
    "s2a.bn1.running_mean.data = torch.tensor(f[\"batch_normalization_8\"][\"batch_normalization_8\"][\"moving_mean:0\"][:])\n",
    "s2a.bn1.running_var.data = torch.tensor(f[\"batch_normalization_8\"][\"batch_normalization_8\"][\"moving_variance:0\"][:])\n",
    "#\n",
    "s2a.conv2.weight.data = torch.tensor(f[\"conv2d_9\"][\"conv2d_9\"][\"kernel:0\"][:].T)\n",
    "s2a.conv2.bias.data = torch.tensor(f[\"conv2d_9\"][\"conv2d_9\"][\"bias:0\"][:])\n",
    "#\n",
    "s2a.bn2.bias.data = torch.tensor(f[\"batch_normalization_9\"][\"batch_normalization_9\"][\"beta:0\"][:])\n",
    "s2a.bn2.weight.data = torch.tensor(f[\"batch_normalization_9\"][\"batch_normalization_9\"][\"gamma:0\"][:])\n",
    "s2a.bn2.running_mean.data = torch.tensor(f[\"batch_normalization_9\"][\"batch_normalization_9\"][\"moving_mean:0\"][:])\n",
    "s2a.bn2.running_var.data = torch.tensor(f[\"batch_normalization_9\"][\"batch_normalization_9\"][\"moving_variance:0\"][:])\n",
    "# stack 2b\n",
    "s2b = model.stack2b\n",
    "s2b[0].conv1.weight.data = torch.tensor(f[\"conv2d_10\"][\"conv2d_10\"][\"kernel:0\"][:].T)\n",
    "s2b[0].conv1.bias.data = torch.tensor(f[\"conv2d_10\"][\"conv2d_10\"][\"bias:0\"][:])\n",
    "#\n",
    "s2b[0].bn1.bias.data = torch.tensor(f[\"batch_normalization_10\"][\"batch_normalization_10\"][\"beta:0\"][:])\n",
    "s2b[0].bn1.weight.data = torch.tensor(f[\"batch_normalization_10\"][\"batch_normalization_10\"][\"gamma:0\"][:])\n",
    "s2b[0].bn1.running_mean.data = torch.tensor(f[\"batch_normalization_10\"][\"batch_normalization_10\"][\"moving_mean:0\"][:])\n",
    "s2b[0].bn1.running_var.data = torch.tensor(f[\"batch_normalization_10\"][\"batch_normalization_10\"][\"moving_variance:0\"][:])\n",
    "#\n",
    "s2b[0].conv2.weight.data = torch.tensor(f[\"conv2d_11\"][\"conv2d_11\"][\"kernel:0\"][:].T)\n",
    "s2b[0].conv2.bias.data = torch.tensor(f[\"conv2d_11\"][\"conv2d_11\"][\"bias:0\"][:])\n",
    "#\n",
    "s2b[0].bn2.bias.data = torch.tensor(f[\"batch_normalization_11\"][\"batch_normalization_11\"][\"beta:0\"][:])\n",
    "s2b[0].bn2.weight.data = torch.tensor(f[\"batch_normalization_11\"][\"batch_normalization_11\"][\"gamma:0\"][:])\n",
    "s2b[0].bn2.running_mean.data = torch.tensor(f[\"batch_normalization_11\"][\"batch_normalization_11\"][\"moving_mean:0\"][:])\n",
    "s2b[0].bn2.running_var.data = torch.tensor(f[\"batch_normalization_11\"][\"batch_normalization_11\"][\"moving_variance:0\"][:])\n",
    "##########\n",
    "s2b[1].conv1.weight.data = torch.tensor(f[\"conv2d_12\"][\"conv2d_12\"][\"kernel:0\"][:].T)\n",
    "s2b[1].conv1.bias.data = torch.tensor(f[\"conv2d_12\"][\"conv2d_12\"][\"bias:0\"][:])\n",
    "#\n",
    "s2b[1].bn1.bias.data = torch.tensor(f[\"batch_normalization_12\"][\"batch_normalization_12\"][\"beta:0\"][:])\n",
    "s2b[1].bn1.weight.data = torch.tensor(f[\"batch_normalization_12\"][\"batch_normalization_12\"][\"gamma:0\"][:])\n",
    "s2b[1].bn1.running_mean.data = torch.tensor(f[\"batch_normalization_12\"][\"batch_normalization_12\"][\"moving_mean:0\"][:])\n",
    "s2b[1].bn1.running_var.data = torch.tensor(f[\"batch_normalization_12\"][\"batch_normalization_12\"][\"moving_variance:0\"][:])\n",
    "#\n",
    "s2b[1].conv2.weight.data = torch.tensor(f[\"conv2d_13\"][\"conv2d_13\"][\"kernel:0\"][:].T)\n",
    "s2b[1].conv2.bias.data = torch.tensor(f[\"conv2d_13\"][\"conv2d_13\"][\"bias:0\"][:])\n",
    "#\n",
    "s2b[1].bn2.bias.data = torch.tensor(f[\"batch_normalization_13\"][\"batch_normalization_13\"][\"beta:0\"][:])\n",
    "s2b[1].bn2.weight.data = torch.tensor(f[\"batch_normalization_13\"][\"batch_normalization_13\"][\"gamma:0\"][:])\n",
    "s2b[1].bn2.running_mean.data = torch.tensor(f[\"batch_normalization_13\"][\"batch_normalization_13\"][\"moving_mean:0\"][:])\n",
    "s2b[1].bn2.running_var.data = torch.tensor(f[\"batch_normalization_13\"][\"batch_normalization_13\"][\"moving_variance:0\"][:])\n",
    "# stack 3a\n",
    "s3a = model.stack3a\n",
    "s3a.conv1.weight.data = torch.tensor(f[\"conv2d_15\"][\"conv2d_15\"][\"kernel:0\"][:].T)\n",
    "s3a.conv1.bias.data = torch.tensor(f[\"conv2d_15\"][\"conv2d_15\"][\"bias:0\"][:])\n",
    "#\n",
    "s3a.bn1.bias.data = torch.tensor(f[\"batch_normalization_14\"][\"batch_normalization_14\"][\"beta:0\"][:])\n",
    "s3a.bn1.weight.data = torch.tensor(f[\"batch_normalization_14\"][\"batch_normalization_14\"][\"gamma:0\"][:])\n",
    "s3a.bn1.running_mean.data = torch.tensor(f[\"batch_normalization_14\"][\"batch_normalization_14\"][\"moving_mean:0\"][:])\n",
    "s3a.bn1.running_var.data = torch.tensor(f[\"batch_normalization_14\"][\"batch_normalization_14\"][\"moving_variance:0\"][:])\n",
    "#\n",
    "s3a.conv2.weight.data = torch.tensor(f[\"conv2d_16\"][\"conv2d_16\"][\"kernel:0\"][:].T)\n",
    "s3a.conv2.bias.data = torch.tensor(f[\"conv2d_16\"][\"conv2d_16\"][\"bias:0\"][:])\n",
    "#\n",
    "s3a.bn2.bias.data = torch.tensor(f[\"batch_normalization_15\"][\"batch_normalization_15\"][\"beta:0\"][:])\n",
    "s3a.bn2.weight.data = torch.tensor(f[\"batch_normalization_15\"][\"batch_normalization_15\"][\"gamma:0\"][:])\n",
    "s3a.bn2.running_mean.data = torch.tensor(f[\"batch_normalization_15\"][\"batch_normalization_15\"][\"moving_mean:0\"][:])\n",
    "s3a.bn2.running_var.data = torch.tensor(f[\"batch_normalization_15\"][\"batch_normalization_15\"][\"moving_variance:0\"][:])\n",
    "# stack 3b\n",
    "s3b = model.stack3b\n",
    "s3b[0].conv1.weight.data = torch.tensor(f[\"conv2d_18\"][\"conv2d_18\"][\"kernel:0\"][:].T)\n",
    "s3b[0].conv1.bias.data = torch.tensor(f[\"conv2d_18\"][\"conv2d_18\"][\"bias:0\"][:])\n",
    "#\n",
    "s3b[0].bn1.bias.data = torch.tensor(f[\"batch_normalization_16\"][\"batch_normalization_16\"][\"beta:0\"][:])\n",
    "s3b[0].bn1.weight.data = torch.tensor(f[\"batch_normalization_16\"][\"batch_normalization_16\"][\"gamma:0\"][:])\n",
    "s3b[0].bn1.running_mean.data = torch.tensor(f[\"batch_normalization_16\"][\"batch_normalization_16\"][\"moving_mean:0\"][:])\n",
    "s3b[0].bn1.running_var.data = torch.tensor(f[\"batch_normalization_16\"][\"batch_normalization_16\"][\"moving_variance:0\"][:])\n",
    "#\n",
    "s3b[0].conv2.weight.data = torch.tensor(f[\"conv2d_19\"][\"conv2d_19\"][\"kernel:0\"][:].T)\n",
    "s3b[0].conv2.bias.data = torch.tensor(f[\"conv2d_19\"][\"conv2d_19\"][\"bias:0\"][:])\n",
    "#\n",
    "s3b[0].bn2.bias.data = torch.tensor(f[\"batch_normalization_17\"][\"batch_normalization_17\"][\"beta:0\"][:])\n",
    "s3b[0].bn2.weight.data = torch.tensor(f[\"batch_normalization_17\"][\"batch_normalization_17\"][\"gamma:0\"][:])\n",
    "s3b[0].bn2.running_mean.data = torch.tensor(f[\"batch_normalization_17\"][\"batch_normalization_17\"][\"moving_mean:0\"][:])\n",
    "s3b[0].bn2.running_var.data = torch.tensor(f[\"batch_normalization_17\"][\"batch_normalization_17\"][\"moving_variance:0\"][:])\n",
    "##########\n",
    "s3b[1].conv1.weight.data = torch.tensor(f[\"conv2d_20\"][\"conv2d_20\"][\"kernel:0\"][:].T)\n",
    "s3b[1].conv1.bias.data = torch.tensor(f[\"conv2d_20\"][\"conv2d_20\"][\"bias:0\"][:])\n",
    "#\n",
    "s3b[1].bn1.bias.data = torch.tensor(f[\"batch_normalization_18\"][\"batch_normalization_18\"][\"beta:0\"][:])\n",
    "s3b[1].bn1.weight.data = torch.tensor(f[\"batch_normalization_18\"][\"batch_normalization_18\"][\"gamma:0\"][:])\n",
    "s3b[1].bn1.running_mean.data = torch.tensor(f[\"batch_normalization_18\"][\"batch_normalization_18\"][\"moving_mean:0\"][:])\n",
    "s3b[1].bn1.running_var.data = torch.tensor(f[\"batch_normalization_18\"][\"batch_normalization_18\"][\"moving_variance:0\"][:])\n",
    "#\n",
    "s3b[1].conv2.weight.data = torch.tensor(f[\"conv2d_21\"][\"conv2d_21\"][\"kernel:0\"][:].T)\n",
    "s3b[1].conv2.bias.data = torch.tensor(f[\"conv2d_21\"][\"conv2d_21\"][\"bias:0\"][:])\n",
    "#\n",
    "s3b[1].bn2.bias.data = torch.tensor(f[\"batch_normalization_19\"][\"batch_normalization_19\"][\"beta:0\"][:])\n",
    "s3b[1].bn2.weight.data = torch.tensor(f[\"batch_normalization_19\"][\"batch_normalization_19\"][\"gamma:0\"][:])\n",
    "s3b[1].bn2.running_mean.data = torch.tensor(f[\"batch_normalization_19\"][\"batch_normalization_19\"][\"moving_mean:0\"][:])\n",
    "s3b[1].bn2.running_var.data = torch.tensor(f[\"batch_normalization_19\"][\"batch_normalization_19\"][\"moving_variance:0\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation parameters fo CIFAR10\n",
    "means = [0.4918687901200927, 0.49185976472299225, 0.4918583862227116]\n",
    "stds  = [0.24697121702736, 0.24696766978537033, 0.2469719877121087]\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=means,\n",
    "    std=stds,\n",
    ")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # 4 pixels are padded on each side, \n",
    "    transforms.Pad(4),\n",
    "    # a 32×32 crop is randomly sampled from the \n",
    "    # padded image or its horizontal flip.\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    # For testing, we only evaluate the single \n",
    "    # view of the original 32×32 image.\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_test = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        cifar_test,\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 16, 1, 1], expected input[32, 32, 16, 16] to have 16 channels, but got 32 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bcf81e479ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     batch_x, batch_y = batch_x.to(device), batch_y.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/resnet/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack2a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcuts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcuts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack2b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcuts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcuts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack3a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcuts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcuts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/resnet/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, shortcuts)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcuts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 16, 1, 1], expected input[32, 32, 16, 16] to have 16 channels, but got 32 channels instead"
     ]
    }
   ],
   "source": [
    "def accuracy(predicted_logits, reference):\n",
    "    \"\"\"Compute the ratio of correctly predicted labels\"\"\"\n",
    "    labels = torch.argmax(predicted_logits, 1)\n",
    "    correct_predictions = labels.eq(reference)\n",
    "    return correct_predictions.sum().float() / correct_predictions.nelement()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "weights_for_avg = []\n",
    "for batch_x, batch_y in test_loader:\n",
    "#     batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "    prediction = model(batch_x)\n",
    "    loss = criterion(prediction, batch_y)\n",
    "    acc = accuracy(prediction, batch_y)\n",
    "    test_accs.append(acc)\n",
    "    test_losses.append(loss)\n",
    "    weights_for_avg.append(len(batch_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0955"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(test_accs, weights=weights_for_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stack3a.conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for child_name, child in model.named_children():\n",
    "    if isinstance(child, nn.BatchNorm2d):\n",
    "        i = i +1\n",
    "        print(child)\n",
    "    else:\n",
    "        if isinstance(child, nn.ModuleList):\n",
    "            for _, child1 in child.named_children():\n",
    "                if isinstance(child1, resnet.block):\n",
    "                    for _, child2 in child1.named_children():\n",
    "                        if isinstance(child2, nn.BatchNorm2d):\n",
    "                            print(child2)\n",
    "                            i = i+1\n",
    "        elif isinstance(child, resnet.block):\n",
    "            for _, child3 in child.named_children():\n",
    "                if isinstance(child3, nn.BatchNorm2d):\n",
    "                    print(child3)\n",
    "                    i = i+1\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
